---
title: "VRCC Analysis Pipeline"
author: "AM, FK, PM"
date: "May 5, 2019"
# contact: "klotzsche@cbs.mpg.de", "aleksander.molak@gmail.com", "pawel.motyka@psych.uw.edu.pl"
output: html_document
chunk_output_type: console
self_contained: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
```

# Import libraries & setup directories

```{r message=FALSE, warning=FALSE}

# Utils
library(dplyr) 
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)

# Plotting and tables
library(ggplot2)
library(sjPlot)

# Statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)

# Load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))

```

<br>

# Build the fulldataset

```{r warning=FALSE}

# Set up the fulldata directory
VRCC_dir         <- here()
data_dir         <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path  <- here("./Data/VRTask/Ratings/Backup_15-07-2019.xlsx")
sess_info_folder <- here('./Data/VRTask/Logfiles/ExpSubjects')

# Build the fulldataset (Behavioral/VR data)
cat('\n\nReading bahavioral and VR data...\n\n')
fulldata <- build_dataset(data_dir)

# Get the summary of questionnaire data
cat('\n\nReading questionnaire data...\n\n')
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)


### Removing the subjects with no cardiac data (temporary - to be decided) 
# # Drop unused data from five subjects
pre_exclusions <- c("S11", "S13", "S18", "S21", "S44")

# from behavioral data:
length(unique(fulldata$ID)) # sample size before
fulldata <- fulldata[!(fulldata$ID %in% pre_exclusions), ]
length(unique(fulldata$ID))  # sample size after

# from questionnaire data:
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))


```

<br>

# Apply further transformations and create additional variables

```{r}

# Drop unused levels
fulldata <- droplevels(fulldata)


```

<br>

# Compute distance errors

```{r}

# Compute distance errors & add to the fulldataset
fulldata <- fulldata %>% 
  mutate(DistanceError = (EstimatedDistance - RealDistance),
         DistanceErrorAbs = abs(DistanceError),
         DistanceErrorNorm = DistanceError / RealDistance,
         DistanceErrorNormAbs = abs(DistanceErrorNorm),
         LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
         AngularErrorRad = compute_angles(EstimatedPosition, TruePosition)) %>% 
  mutate(totTrial = Trial + (Round - 1) * max(Trial)) # Labels the trials with sequential numbers over the whole experiment (1-720)   

# insert NAs when no estimation was made
fulldata$LocalizationError[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$AngularErrorRad[is.na(fulldata$EstimatedDistance)] <- NA

```

<br>

* ### Add cardio information to the fulldataset

```{r warning=FALSE, message = FALSE}

# get the list of subjects with full ecg data
subjects_list <- list.files(here("Data/VRTask/Cardio/ExpSubjects/02_Peaks/Events"))
subjects_list <- str_remove(subjects_list, "VRCC_")
subjects_list <- str_remove(subjects_list, ".csv")

cardio_data   <- NULL

# add cardio data
for (subj_ID in subjects_list) {                               
  cardio_temp <- get_cardio_info(fulldata, subj_ID)
  cardio_data <- bind_rows(cardio_data, cardio_temp)
}

# Join the data
fulldata <- full_join(fulldata, cardio_data)                 

# Save the preprocessed data
#write.csv(fulldata, paste0(VRCC_dir, "/Data/VRTask/VRCC_fulldata_consolidated"), row.names = F)

# Read the preprocessed data
#fulldata <- read.csv(file = paste0(VRCC_dir,"/Data/VRTask/VRCC_fulldata_consolidated"))


```


<br>

## Exclusions based on localization errors (behavioral & trial-based)


```{r}

# Add unique row ID
fulldata$row_ID <- paste0(fulldata$ID, '_', fulldata$Round, '_', fulldata$Trial)
fulldata$ID <- as.factor(fulldata$ID)

# remove trials with no responses (NAs for distance estimations)
data_filt_behav <- fulldata[!is.na(fulldata$EstimatedDistance),]
nrow(fulldata)-nrow(data_filt_behav) # how many trials
length(unique(fulldata$ID[is.na(fulldata$EstimatedDistance)])) # from how many participants

# remove trials with no cardiac data (either due to temporary absence of ecg signal: 88 trials or too noisy signal: 24 trials)
data_filt_ecg <- data_filt_behav[!is.na(data_filt_behav$systolength),]
nrow(data_filt_behav)-nrow(data_filt_ecg)

# save consolidated data after removal of NAs
data <- data_filt_ecg
rm(data_filt_behav)
rm(data_filt_ecg)

##### TRIAL-BASED #####

# Remove trials with untypically large Localization Errors within subject (LE): LE > avg(LE) + 3*sd(LE)
thrshlds_b <- data %>% 
            group_by(ID) %>% 
            summarize(thrsh_hi = mean(LocalizationError, na.rm = TRUE) + 3 * sd(LocalizationError, na.rm = TRUE)) 


fullfltrd_1b <- inner_join(data, thrshlds_b, by = 'ID') %>% 
               filter(LocalizationError <= thrsh_hi) %>% 
               select(-c(thrsh_hi))


# How many trials were excluded in total?
cat('How many trials were excluded in total?\n')
cat(dim(data)[1] - dim(fullfltrd_1b)[1])

# What percent of trials should be removed at the subject level?
incl_b      <- data    %>% group_by(ID) %>% count()
excl_trial_b <- fullfltrd_1b %>% group_by(ID) %>% count()
comparison_b <- data.frame(incl_b, excl_trial_b)
comparison_b <- comparison_b %>% select(ID, n, n.1)
colnames(comparison_b) <- c('ID', 'INCL', 'EXCL')

# What percent of trials were removed per subject?
comparison_b$diff_trials <- comparison_b$INCL - comparison_b$EXCL
comparison_b$percent_rm  <- (comparison_b$diff_trials / comparison_b$INCL) * 100
describe(comparison_b$percent_rm) # outliers in %
describe(comparison_b$diff_trials) # outlier in absolute numbers
hist(comparison_b$diff_trials, breaks = 20, xlab = "Number of outlier trials - LE", ylab = "Number of subjects", main = "")

# How many subjects have more than 30% of trials removed?
#cat('How many subjects have more than 30% of trials removed?\n')
#cat(dim(comparison_b %>% filter(percent_rm > .3))[1])


# assign a variable specyfing whether LE value is outlier (alternative/double check)
for (s in unique(data$ID)){
for (t in unique(data$totTrial[data$ID == s])) {
  
ifelse(data$LocalizationError[data$ID == s & data$totTrial == t] > thrshlds_b$thrsh_hi[thrshlds_b$ID==s], outlier <- "outlier", outlier <- "non_outlier")   
data$LE_outlier[data$ID == s & data$totTrial == t] <- outlier 
}
}

# double check - how many outliers?
nrow(data[data$LE_outlier == "outlier",])

# Exlploratory plot (behavioral data) (export 5 x 5 cm)
group_col <- as.character(data$LE_outlier)            
group_col[group_col == "outlier"] <- scales::alpha("darkorange", 0.5)
group_col[group_col == "non_outlier"] <- scales::alpha("gray20", 0.2)

scatter.smooth(data$RealDistance, data$EstimatedDistance, xlim = c(1.4,5.6), ylim = c(0.5,11.5), cex = 0.2, col = group_col, xlab = "Real Distance", ylab = "Estimated Distance")

# create an identity line using a customized linear model
x<-0:7
y<-0:7
new <- data.frame(x = seq(0, 6, 0.1))
lines(new$x, predict(lm(y~x), new),col= scales::alpha("dodgerblue", alpha = 0.7),lty= 2, lwd = 1.6)

# plot without outliers
d <- data[data$LE_outlier == "non_outlier",]
scatter.smooth(d$RealDistance, d$EstimatedDistance, xlim = c(1.4,5.6), ylim = c(0.5,8.5), cex = 0.05, col = scales::alpha("gray20", 0.4) , xlab = "Real Distance", ylab = "Estimated Distance")

# create an identity line using a customized linear model
x<-0:7
y<-0:7
new <- data.frame(x = seq(0, 6, 0.1))
lines(new$x, predict(lm(y~x), new),col= scales::alpha("dodgerblue", alpha = 0.8),lty= 2, lwd = 1.6)

```

## Exclusions based on distance estimates (behavioral & subject-based)


```{r}


##### SUBJECT-BASED #####

# Remove subjects with more than three standard deviations above or below the sample mean of Distance Error

# Get subject means
ID_means_b <- fullfltrd_1b %>% group_by(ID) %>% 
                            summarize(mean_DE = mean(DistanceError, na.rm = TRUE))

# Get sample mean & SD
grand_mean_DistanceError <- mean(ID_means_b$mean_DE)
grand_sd_DistanceError   <- sd(ID_means_b$mean_DE)

# Filter-out subjects
fltrd_IDs_b <- ID_means_b %>% filter(mean_DE < grand_mean_DistanceError + 3 * grand_sd_DistanceError) %>% 
                          filter(mean_DE > grand_mean_DistanceError - 3 * grand_sd_DistanceError) 

# Join frames on ID (filter the full data)
fullfltrd_2b <- inner_join(fltrd_IDs_b, fullfltrd_1b, by = 'ID') %>%
               select(-mean_DE)

# mean DE 
hist(fltrd_IDs_b$mean_DE, breaks = 20)

# How many participants were excluded?
cat('How many participants were excluded?\n')
cat(dim(fullfltrd_1b %>% group_by(ID) %>% count())[1] - dim(fullfltrd_2b %>% group_by(ID) %>% count())[1])

# Which ones?
cat('Which ones?\n')
setdiff(ID_means_b, fltrd_IDs_b)

```


## Exclusions based on t_wave ends (for binary analysis)


```{r}
##### TRIAL-BASED #####

# Remove trials with untypically large/short systole lengths
thrshlds_t <- data %>% 
            group_by(ID) %>% 
            summarize(thrsh_hi = mean(systolength, na.rm = TRUE) + 4 * sd(systolength, na.rm = TRUE),                        thrsh_lo = mean(systolength, na.rm = TRUE) - 4 * sd(systolength, na.rm = TRUE)) 

# Remove rows with NA in cardiac data
data_filt <- data %>%  filter(!(is.na(systolength)))

fullfltrd_1t <- inner_join(data_filt, thrshlds_t, by = 'ID') %>% 
               filter(systolength < thrsh_hi) %>% 
               filter(systolength > thrsh_lo) %>%
               select(-c(thrsh_lo, thrsh_hi))


# How many trials were excluded in total?
cat('How many trials were excluded in total?\n')
cat(dim(data_filt)[1] - dim(fullfltrd_1t)[1])

# What percent of trials should be removed at the subject level?

incl_t       <- data_filt %>% group_by(ID) %>% count()
excl_trial_t <- fullfltrd_1t %>% group_by(ID) %>% count()
comparison_t <- data.frame(incl_t, excl_trial_t)
comparison_t <- comparison_t %>% select(ID, n, n.1)
colnames(comparison_t) <- c('ID', 'INCL', 'EXCL')

# What percent of trials were removed per subject?
comparison_t$diff_trials <- comparison_t$INCL - comparison_t$EXCL
comparison_t$percent_rm  <- (comparison_t$diff_trials / comparison_t$INCL) * 100
describe(comparison_t$diff_trials)
describe(comparison_t$percent_rm)
hist(comparison_t$diff_trials, breaks = 20, xlab = "Number of outlier systole lengths", ylab = "Subjects count", main = "", col = "firebrick4")

# How many subjects have more than 30% of trials removed?
# cat('How many subjects have more than 30% of trials removed?\n')
# cat(dim(comparison_t %>% filter(percent_rm > .3))[1])


# assign a variable specyfing whether LE value is outlier (alternative/double check)
for (s in unique(data$ID)){
for (t in unique(data$totTrial[data$ID == s])) {
  
ifelse(data$systolength[data$ID == s & data$totTrial == t] > thrshlds_t$thrsh_hi[thrshlds_t$ID==s], outlier <- "outlier", outlier <- "non_outlier") 

ifelse(data$systolength[data$ID == s & data$totTrial == t] < thrshlds_t$thrsh_lo[thrshlds_t$ID==s], outlier <- "outlier", outlier <- outlier)    
data$SYS_outlier[data$ID == s & data$totTrial == t] <- outlier 
}
}

# double check - how many outliers?
nrow(data[data$SYS_outlier == "outlier",])

# Exlploratory plot (behavioral data) (export 5 x 5 cm)
group_col <- as.character(data$SYS_outlier)            
group_col[group_col == "outlier"] <- scales::alpha("darkorange", 0.7)
group_col[group_col == "non_outlier"] <- scales::alpha("gray20", 0.2)

scatter.smooth(data$RRLength, data$systolength, xlim = c(min(data$RRLength),max(data$RRLength)), ylim = c(min(data$systolength),max(data$systolength)), cex = 0.2, col = group_col, xlab = "RR interval", ylab = "Systole length")

# scatter.smooth(data$RRLength[data$ID == "S33"], data$systolength[data$ID == "S33"], xlim = c(min(data$RRLength),max(data$RRLength)), ylim = c(min(data$systolength),max(data$systolength)), cex = 0.2, col = group_col, xlab = "RR interval", ylab = "Systole length")

nrow(data[data$SYS_outlier == "outlier",])
d <- data[data$SYS_outlier == "non_outlier",]

scatter.smooth(d$RRLength, d$systolength, xlim = c(min(d$RRLength),max(d$RRLength)), ylim = c(min(d$systolength),max(d$systolength)), cex = 0.1, col = scales::alpha("gray20", 0.3), xlab = "RR interval", ylab = "Systole length")



```




```{r}

##### SUBJECT-BASED #####


# Remove subjects with more than three standard deviations above or below the sample mean of systole length

# Get subject means
ID_means_t <- fullfltrd_1t %>% group_by(ID) %>% 
                            summarize(mean_SL = mean(systolength, na.rm = TRUE))

# Get sample mean & SD
grand_mean_SystoleLength <- mean(ID_means_t$mean_SL)

grand_sd_SystoleLength  <- sd(ID_means_t$mean_SL)

# Filter-out subjects
fltrd_IDs_t <- ID_means_t %>% filter(mean_SL < grand_mean_SystoleLength + 4 * grand_sd_SystoleLength) %>% 
                          filter(mean_SL > grand_mean_SystoleLength - 4 * grand_sd_SystoleLength) 

# Join frames on ID (filter the full data)
fullfltrd_2t <- inner_join(fltrd_IDs_t, fullfltrd_1t, by = 'ID') %>%
               select(-mean_SL)


# How many participants were excluded?
cat('How many participants were excluded?\n')
cat(dim(fullfltrd_1t %>% group_by(ID) %>% count())[1] - dim(fullfltrd_2t %>% group_by(ID) %>% count())[1])

# Which ones?
cat('Which ones?\n')
setdiff(ID_means_t, fltrd_IDs_t)
```


## Join data after exclusions

```{r}
ids_2b <- fullfltrd_2b %>% group_by(row_ID) %>% select(row_ID) %>% unique()
ids_2t <- fullfltrd_2t %>% group_by(row_ID) %>% select(row_ID) %>% unique()
ids    <- inner_join(ids_2b, ids_2t, by = 'row_ID')

fullfltrd_binary <- inner_join(ids, fullfltrd_2b, by = 'row_ID', copy = FALSE)
```



<br>

* ### Explore the relationship between Distance Error and Real Distance (possibly the side-branch in the final code)

```{r, fig.height = 3, fig.width = 4}

# VRCC_behav_pilots includes other attempts of approaching this issue

# for (p in unique(fulldata$ID)) {
# 
# subdata <- fulldata[fulldata$ID == p,]
#   
# Figure <- ggplot(data = subdata, aes(x = RealDistance, y = DistanceError)) + 
#   geom_point(col = "grey 15", alpha = 0.3, size = 2.5, shape = 18) + 
#   geom_smooth(col = "grey8", method = "loess", level=0.95, alpha = 0.8) + 
#   labs(y = "Distance Error", x = "True Distance") +   
#   ggtitle(p) +
#   theme_classic() + 
#   theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 17), axis.text=element_text(size=15),  axis.title=element_text(size=15)) +
#   scale_x_continuous(limits= c(min(fulldata$RealDistance), max(fulldata$RealDistance)), expand = c(0.01,0.01)) +
#   scale_y_continuous(limits= c(min(fulldata$DistanceError), max(fulldata$DistanceError)), expand = c(0.01,0.01)) 
# 
# plot(Figure)
# 
# }


```

<br>

# Main analysis - Hypothesis 1

<br>

* ### Check if the distance error ($DE$) differs between threatening and non-threatening trials

```{r message=FALSE}

## Exploratory plots

# Check the distribution of DE (all data points - not averaged for individuals)
ggplot(fulldata, aes(x = DistanceError, fill = FearObject)) + 
                           geom_histogram(alpha = .7) + 
                           xlab('Distance Error') + 
                           ylab('Value') + 
                           theme_minimal()
qqPlot(fulldata$DistanceError)

## Testing the hypothesis 1. (T-test)


####### SAMPLE DATA ########### REMOVE AFTER ###########
sampled_ids  <- sample(unique(fullfltrd_binary$ID), 20)
sampled_data <- fullfltrd_binary %>% filter(ID %in% sampled_ids)
########################################################

# Derive individual means of distance error for threatening and non-threatening objects

data_by_id <- sampled_data %>%
  group_by(ID) %>%
  summarize(mean_threat     = mean(DistanceError[FearObject == "True"]), # threatening objects
            mean_non_threat = mean(DistanceError[FearObject == "False"])) # non-threatening objects

data_by_id_2 <- sampled_data %>%
  group_by(ID) %>%
  summarize(mean_threat_syst      = mean(DistanceError[FearObject == "True" & c_phase == 'systole']), 
            mean_non_threat_syst  = mean(DistanceError[FearObject == "False" & c_phase == 'systole']),
            mean_threat_diast     = mean(DistanceError[FearObject == "True" & c_phase == 'diastole']), 
            mean_non_threat_diast = mean(DistanceError[FearObject == "False" & c_phase == 'diastole'])
            ) 

d <- data_by_id_2 
d$diff <- d$mean_threat_syst - d$mean_threat_diast
mean(d$mean_threat_syst)
mean(d$mean_threat_diast)
hist(d$diff)

#shapiro.test(data_ID$mean_threat)
#shapiro.test(data_ID$mean_non_threat)

# Employ paired t-test to determine whether distance error differs between the threatening and non-threatening objects
t.test(data_by_id$mean_threat, data_by_id$mean_non_threat, alt = "two.sided", conf = 0.95, paired = T) 

t.test(data_by_id_2$mean_threat_syst, data_by_id_2$mean_threat_diast, alt = "two.sided", conf = 0.95, paired = T) 
## PM: we could even consider "one.sided" test here
# Perfom Wilcoxon signed-rank test:  
#wilcox.test(data_ID$mean_threat, data_ID$mean_threat, paired = T)

# Calculate Cohen's d
cohen.d(data_ID$mean_threat, data_ID$mean_non_threat, paired = T)

# Show summary statistics for threatening and non-threatening objects:
mean(data_ID$mean_threat)
sd(data_ID$mean_threat)

mean(data_ID$mean_non_threat)
sd(data_ID$mean_non_threat)

# Check the normality of dependent variable distribution
#shapiro.test(data_ID$mean_threat)
#shapiro.test(data_ID$mean_non_threat)

# Employ paired t-test to determine whether distance error differs between the threatening and non-threatening objects
t.test(data_ID$mean_threat, data_ID$mean_non_threat, alt = "two.sided", conf = 0.95, paired = T) ## PM: we could even consider "one.sided" test here
# Perfom Wilcoxon signed-rank test:  
#wilcox.test(data_ID$mean_threat, data_ID$mean_threat, paired = T)

# Calculate Cohen's d
cohen.d(data_ID$mean_threat, data_ID$mean_non_threat, paired = T)

# Show summary statistics for threatening and non-threatening objects:
mean(data_ID$mean_threat)
sd(data_ID$mean_threat)

mean(data_ID$mean_non_threat)
sd(data_ID$mean_non_threat)

# show number of participants with lower distance error values for threatening objects
nrow(data_ID[data_ID$mean_threat < data_ID$mean_non_threat,])

# Calculate Bayes Factor
ttestBF(data_ID$mean_threat, data_ID$mean_non_threat, paired = T)


## Testing the hypothesis 1. (Regression) #PM: This is to some extent analogous to further sections (and only a draft for now); We need to discuss our approach towards testing H1 with regression

null_model_H1 <- lmer(DistanceError ~ 1 + (1 + RealDistance | ID), data = fulldata)
summary(null_model_H1)

model_H1 <- lmer(DistanceError ~ FearObject + (1 + RealDistance | ID), data = fulldata)
summary(model_H1)

```

<br>

* ### Hypothesis 1: Multilevel model - null model

### REMEMBER TO EXCLUDE `c_phase == 'buffer'` FROM BINARY ANALYSIS ####

<br>

```{r}
# Null model
null_model_1 <- lmer(DistanceError ~ (1|ID), 
                     data = fulldata)
# **FK 23-07-19**: In the prereg we put forward a slightly different null model (p. 8) for testing
#                  the 2nd hypothesis:
#                  DistErr ~ 1 + (1 + DistTrue | ID)
#                  Wouldn't it be coherent to use the same one here as well? Opinions welcome.
# **AM 27-07-19**: In my understanding adding (1 + DistTrue ....) would mean that we add random slopes of true 
#                  distance grouped by ID to the model. I'm not sure if I understand the rationle behind this at the 
#                  moment. What would that mean to us?

summary_1_1 <- summary(null_model_1)
summary_1_1 

```

<br>

* #### Compute ICC of a null model to check if multilevel structure is justified

<br>

```{r}
# AM (2019-07-21): This will be moved to utility functions. This function only works properly for null models.

ICC <- function(model) {
  
  variances = data.frame(summary(model)$varcor)
  
  tau_00    = variances %>% 
                filter(var1 == '(Intercept)') %>% 
                select(vcov) %>% 
                .$vcov
  sigma_2   = variances %>% 
                filter(grp == 'Residual') %>% 
                select(vcov) %>% 
                .$vcov
  
  tau_00 / (tau_00 + sigma_2)
}

# AM (2019-07-21): The below code should stay here:

ICC(null_model_1)

```

<br>

* ### Hypothesis 1: Multilevel model - full model

<br>

```{r}
# Null model
full_model_1 <- lmer(DistanceError ~ FearObject + (1 + FearObject|ID), 
                     data = fulldata)
# **FK 23-07-19**: If we change the null model, the rand. effect DistTrue should probably go in here
#                  as well. Also this makes the model comp. with the next model (2a) possible as they
#                  then are nested. (Pls correct me if I'm bullshitting.)
# **AM 27-07-19**: Yes, totally agree. I propose that we discuss the null model and act here accordingly.

summary_1_2 <- summary(full_model_1)

```

<br>

* ### Hypothesis 1: Compare the two models

```{r}

lrtest(null_model_1, full_model_1)

```

<br>

## Testing the main hypothesis (2a) using multilevel modeling and a circular predictor

<br>

```{r}
print('Implement this...')

```

<br>

## Testing the main hypothesis (2b) using mutlilevel modeling and a binary predictor

<br>

```{r}
print('Implement this...')

```

<br>

# Exploratory / additional analyses

```{r}

# Needs aggregation of depedent variables for each ID

mean_error_per_fear <- fulldata %>%
                          group_by(FearObject) %>%
                            summarise(MeanDistanceError = mean(DistanceError, na.rm=T),
                                      MeanDistanceErrorNorm = mean(DistanceErrorNorm, na.rm=T),
                                      MeanDistanceErrorAbs = mean(DistanceErrorAbs, na.rm=T))

mean_error_per_animal <- fulldata %>%
                          group_by(Stimulus) %>%
                            summarise(MeanDistanceError = mean(DistanceError, na.rm=T),
                                      MeanDistanceErrorNorm = mean(DistanceErrorNorm, na.rm=T),
                                      MeanDistanceErrorAbs = mean(DistanceErrorAbs, na.rm=T))
# 
# mean_dist_per_fear
# mean_dist_per_animal
      
```

