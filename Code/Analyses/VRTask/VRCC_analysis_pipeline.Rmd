---
title: "VRCC Analysis Pipeline"
author: "AM, FK, PM"
date: "May 5, 2019"
# contact: "klotzsche@cbs.mpg.de", "aleksander.molak@gmail.com"
output: html_document
chunk_output_type: console
self_contained: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
```

# Import libraries & setup directories

```{r message=FALSE, warning=FALSE}

# Utils
library(dplyr) 
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)

# Plotting and tables
library(ggplot2)
library(sjPlot)

# Statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
require(effsize)

# Load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))

```

<br>

# Build the dataset

```{r warning=FALSE}

# Set up the data directory
VRCC_dir        <- here()
data_dir        <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path <- here("Data/VRTask/VRCC_questionnaires.xlsx")

# Build the dataset
fulldata <- build_dataset(data_dir)

# Read and filter behavioral data
qstnr_data <- read_questionnaire_data(qstnr_data_path, filter_pilot = TRUE)

```

<br>

# Apply further transformations and create additional variables

```{r}

# Drop unused levels
fulldata <- droplevels(fulldata)

```

<br>

* ### Compute distance errors

```{r}

# Compute distance errors & add to the dataset
fulldata <- fulldata %>% 
  mutate(DistanceError = (EstimatedDistance - RealDistance),
         DistanceErrorAbs = abs(DistanceError),
         DistanceErrorNorm = DistanceError / RealDistance,
         DistanceErrorNormAbs = abs(DistanceErrorNorm)) %>% 
  mutate(totTrial = Trial + (Round - 1) * max(Trial)) #Labels the trials with sequential numbers over the whole experiment (1-720)   


```

<br>

* ### Add cardio information to the dataset

```{r warning=FALSE}

subjects_list <- fulldata %>%
                  select(ID) %>%
                  distinct()

cardio_data   <- NULL

for (subject in subjects_list$ID) {                               
  cardio_temp <- get_cardio_info(fulldata, subject)
  cardio_data <- bind_rows(cardio_data, cardio_temp)
}

# Join the data
fulldata <- full_join(fulldata, cardio_data)                 

```

<br>

* ### Explore the relationship between Distance Error and Real Distance (possibly the side-branch in the final code)

```{r, fig.height = 3, fig.width = 4}

# VRCC_behav_pilots includes other attempts of approaching this issue

for (p in unique(fulldata$ID)) {

subdata <- fulldata[fulldata$ID == p,]
  
Figure <- ggplot(data = subdata, aes(x = RealDistance, y = DistanceError)) + 
  geom_point(col = "grey 15", alpha = 0.3, size = 2.5, shape = 18) + 
  geom_smooth(col = "grey8", method = "loess", level=0.95, alpha = 0.8) + 
  labs(y = "Distance Error", x = "True Distance") +   
  ggtitle(p) +
  theme_classic() + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 17), axis.text=element_text(size=15),  axis.title=element_text(size=15)) +
  scale_x_continuous(limits= c(min(fulldata$RealDistance), max(fulldata$RealDistance)), expand = c(0.01,0.01)) +
  scale_y_continuous(limits= c(min(fulldata$DistanceError), max(fulldata$DistanceError)), expand = c(0.01,0.01)) 

plot(Figure)

}


```

<br>

# Main analysis - Hypothesis 1

<br>

* ### Check if the distance error ($DE$) differs between threatening and non-threatening trials

```{r message=FALSE}

## Exploratory plots

# Check the distribution of DE (all data points - not averaged for individuals)
ggplot(fulldata, aes(x = DistanceError, fill = FearObject)) + 
                           geom_histogram(alpha = .7) + 
                           xlab('Distance Error') + 
                           ylab('Value') + 
                           theme_minimal()
qqPlot(fulldata$DistanceError)

## Testing the hypothesis 1. (T-test)

# Derive individual means of distance error for threatening and non-threatening objects
data_ID <- fulldata %>%
  group_by(ID) %>%
  summarize(mean_threat     = mean(DistanceError[FearObject == "True"]), # threatening objects
            mean_non_threat = mean(DistanceError[FearObject == "False"])) # non-threatening objects

# Check the normality of dependent variable distribution
#shapiro.test(data_ID$mean_threat)
#shapiro.test(data_ID$mean_non_threat)

# Employ paired t-test to determine whether distance error differs between the threatening and non-threatening objects
t.test(data_ID$mean_threat, data_ID$mean_non_threat, alt = "two.sided", conf = 0.95, paired = T) ## PM: we could even consider "one.sided" test here
# Perfom Wilcoxon signed-rank test:  
#wilcox.test(data_ID$mean_threat, data_ID$mean_threat, paired = T)

# Calculate Cohen's d
cohen.d(data_ID$mean_threat, data_ID$mean_non_threat, paired = T)

# Show summary statistics for threatening and non-threatening objects:
mean(data_ID$mean_threat)
sd(data_ID$mean_threat)

mean(data_ID$mean_non_threat)
sd(data_ID$mean_non_threat)

# show number of participants with lower distance error values for threatening objects
nrow(data_ID[data_ID$mean_threat < data_ID$mean_non_threat,])

# Calculate Bayes Factor
ttestBF(data_ID$mean_threat, data_ID$mean_non_threat, paired = T)


## Testing the hypothesis 1. (Regression) #PM: This is to some extent analogous to further sections (and only a draft for now); We need to discuss our approach towards testing H1 with regression

null_model_H1 <- lmer(DistanceError ~ 1 + (1 + RealDistance | ID), data = fulldata)
summary(null_model_H1)

model_H1 <- lmer(DistanceError ~ FearObject + (1 + RealDistance | ID), data = fulldata)
summary(model_H1)

```

<br>

* ### Hypothesis 1: Multilevel model - null model

<br>

```{r}
# Null model
null_model_1 <- lmer(DistanceError ~ (1|ID), 
                     data = fulldata)
# **FK 23-07-19**: In the prereg we put forward a slightly different null model (p. 8) for testing
#                  the 2nd hypothesis:
#                  DistErr ~ 1 + (1 + DistTrue | ID)
#                  Wouldn't it be coherent to use the same one here as well? Opinions welcome.
# **AM 27-07-19**: In my understanding adding (1 + DistTrue ....) would mean that we add random slopes of true 
#                  distance grouped by ID to the model. I'm not sure if I understand the rationle behind this at the 
#                  moment. What would that mean to us?

summary_1_1 <- summary(null_model_1)
summary_1_1 

```

<br>

* #### Compute ICC of a null model to check if multilevel structure is justified

<br>

```{r}
# AM (2019-07-21): This will be moved to utility functions. This function only works properly for null models.

ICC <- function(model) {
  
  variances = data.frame(summary(model)$varcor)
  
  tau_00    = variances %>% 
                filter(var1 == '(Intercept)') %>% 
                select(vcov) %>% 
                .$vcov
  sigma_2   = variances %>% 
                filter(grp == 'Residual') %>% 
                select(vcov) %>% 
                .$vcov
  
  tau_00 / (tau_00 + sigma_2)
}

# AM (2019-07-21): The below code should stay here:

ICC(null_model_1)

```

<br>

* ### Hypothesis 1: Multilevel model - full model

<br>

```{r}
# Null model
full_model_1 <- lmer(DistanceError ~ FearObject + (1 + FearObject|ID), 
                     data = fulldata)
# **FK 23-07-19**: If we change the null model, the rand. effect DistTrue should probably go in here
#                  as well. Also this makes the model comp. with the next model (2a) possible as they
#                  then are nested. (Pls correct me if I'm bullshitting.)
# **AM 27-07-19**: Yes, totally agree. I propose that we discuss the null model and act here accordingly.

summary_1_2 <- summary(full_model_1)

```

<br>

* ### Hypothesis 1: Compare the two models

```{r}

lrtest(null_model_1, full_model_1)

```

<br>

## Testing the main hypothesis (2a) using multilevel modeling and a circular predictor

<br>

```{r}
print('Implement this...')

```

<br>

## Testing the main hypothesis (2b) using mutlilevel modeling and a binary predictor

<br>

```{r}
print('Implement this...')

```

<br>

# Exploratory / additional analyses

```{r}

# Needs aggregation of depedent variables for each ID

mean_error_per_fear <- fulldata %>%
                          group_by(FearObject) %>%
                            summarise(MeanDistanceError = mean(DistanceError, na.rm=T),
                                      MeanDistanceErrorNorm = mean(DistanceErrorNorm, na.rm=T),
                                      MeanDistanceErrorAbs = mean(DistanceErrorAbs, na.rm=T))

mean_error_per_animal <- fulldata %>%
                          group_by(Stimulus) %>%
                            summarise(MeanDistanceError = mean(DistanceError, na.rm=T),
                                      MeanDistanceErrorNorm = mean(DistanceErrorNorm, na.rm=T),
                                      MeanDistanceErrorAbs = mean(DistanceErrorAbs, na.rm=T))
# 
# mean_dist_per_fear
# mean_dist_per_animal
      
```

