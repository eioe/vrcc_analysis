---
title: <font size="5">**VRCC -- preprocessing **</font> 
author: <br> <font size="4"> Pawel Motyka, Felix Klotzsche, Aleksander Molak </font> <br>  *pmotyka@psych.pan.pl*  *klotzsche@cbs.mpg.de* *aleksander.molak@gmail.com*
date: <font size="3"> April 2021  </font>
output: html_document
chunk_output_type: console
self_contained: no

--- 

&nbsp;
<font size="4">
**List of sections**:

1. Load required packages, utils, and data [S1](#S1)
2. Compute distance measures [S2](#S2)
3. Determine cardiac phases [S3](#S3)
4. Exclusions based on localization errors (individual trials) [S4](#S4)
5. Exclusions based on distance errors (individual subjects) [S5](#S5)
6. Exclusions based on cardiac data (individual trials) [S6](#S6)
7. Remove identified trials and save the preprocessed data [S7](#S7)

<a name="S1"></a>
&nbsp;

#####**1. Load required packages, utils, and data** 

```{r message=FALSE, warning=FALSE}

# r setup
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'

# utils
library(dplyr) 
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
library(dplR)

# plotting and tables
library(ggplot2)
library(sjPlot)

# statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)

# load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/stats_utils.r"))


# set up the fulldata directory
VRCC_dir         <- here()
data_dir         <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path  <- here("./Data/VRTask/Ratings/Ratings_clean.xlsx")
sess_info_folder <- here('./Data/VRTask/Logfiles/ExpSubjects')

# build the fulldataset (Behavioral/VR data)
cat('\n\nReading bahavioral and VR data...\n\n')
fulldata <- build_dataset(data_dir, part='main')
traindata <- build_dataset(data_dir, part='training')

# get the summary of questionnaire data
cat('\n\nReading questionnaire data...\n\n')
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)

# specify unused data from five subjects (different technical issues)
pre_exclusions <- c("S11", "S13", "S18", "S21", "S44")

# remove five subjects from behavioral data
length(unique(fulldata$ID)) # sample size before
fulldata <- fulldata[!(fulldata$ID %in% pre_exclusions), ]
length(unique(fulldata$ID))  # sample size after

# remove five subjects from questionnaire data
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))

# drop unused levels
fulldata <- droplevels(fulldata)

```

<a name="S2"></a>
&nbsp;

#####**2. Compute distance measures** 

```{r}

# compute distance measures & add to the dataset
fulldata <- fulldata %>% 
  mutate(DistanceError = (EstimatedDistance - RealDistance),
         DistanceErrorAbs = abs(DistanceError),
         DistanceErrorNorm = (DistanceError / RealDistance) * 100,
         DistanceErrorNormAbs = abs(DistanceErrorNorm),
         LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
         LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
         AngularErrorRadAbs = compute_angles(EstimatedPosition, TruePosition, abs_value = TRUE),
         AngularErrorRad = compute_angles(EstimatedPosition, TruePosition, abs_value = FALSE)) %>% 
  mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)   

# insert NAs when no estimation was made
fulldata$LocalizationError[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$LocalizationErrorNorm[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$AngularErrorRad[is.na(fulldata$EstimatedDistance)] <- NA

```

```{r}

# compute distance measures & add to the dataset
traindata <- traindata %>% 
  mutate(DistanceError = (EstimatedDistance - RealDistance),
         DistanceErrorAbs = abs(DistanceError),
         DistanceErrorNorm = (DistanceError / RealDistance) * 100,
         DistanceErrorNormAbs = abs(DistanceErrorNorm),
         LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
         LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
         AngularErrorRad = compute_angles(EstimatedPosition, TruePosition)) %>% 
  mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)   

# insert NAs when no estimation was made
traindata$LocalizationError[is.na(traindata$EstimatedDistance)] <- NA
traindata$LocalizationErrorNorm[is.na(traindata$EstimatedDistance)] <- NA
traindata$AngularErrorRad[is.na(traindata$EstimatedDistance)] <- NA

td <- traindata %>% 
  mutate(EstDist_man = compute_euclidean_distances(EstimatedPosition, HeadsetPosition),
         RealDist_man = compute_euclidean_distances(TruePosition, HeadsetPosition),
         DistErr_man = (EstDist_man - RealDist_man))

td <- td %>% 
  mutate(DE_diff = (DistErr_man - DistanceError))

```

```{r}
fd <- fulldata %>% 
  mutate(EstDist_man = compute_euclidean_distances(EstimatedPosition, HeadsetPosition),
         RealDist_man = compute_euclidean_distances(TruePosition, HeadsetPosition),
         DistErr_man = (EstDist_man - RealDist_man))

fd <- fd %>% 
  mutate(DE_diff = (DistErr_man - DistanceError))

```



<a name="S3"></a>
&nbsp;

#####**3. Determine cardiac phases** 

```{r warning=FALSE, message = FALSE}

# get the list of subjects with full ecg data
subjects_list <- list.files(here("Data/VRTask/Cardio/ExpSubjects/02_Peaks/Events"))
subjects_list <- str_remove(subjects_list, "VRCC_")
subjects_list <- str_remove(subjects_list, ".csv")
cardio_data   <- NULL


read_cardiodata_from_disc = TRUE
path_cardiodata <- file.path(here("Data/VRTask/Cardio/", "cardio_data_tmp.rds"))

if (read_cardiodata_from_disc) {
  cardio_data <- readRDS(path_cardiodata)
} else {
  # add cardiac data
  for (subj_ID in subjects_list) {                               
    cardio_temp <- get_cardio_info(fulldata, subj_ID)
    cardio_data <- bind_rows(cardio_data, cardio_temp)
    saveRDS(cardio_data, path_cardiodata)
  }
}

# join the data
fulldata <- full_join(fulldata, cardio_data)                 
# save the preprocessed data (optional)
#write.csv(fulldata, paste0(VRCC_dir, "/Data/VRTask/VRCC_data_unfiltered"), row.names = F)
# read the preprocessed data (optional)
#fulldata <- read.csv(file = paste0(VRCC_dir,"/Data/VRTask/VRCC_data_unfiltered"))

```

<a name="S4"></a>
&nbsp;

#####**4. Exclusions based on localization errors (individual trials)** 

```{r}

# add unique row ID
fulldata$row_ID <- paste0(fulldata$ID, '_', fulldata$Round, '_', fulldata$Trial)
fulldata$ID <- as.factor(fulldata$ID)

# remove trials with no distance estimation (NAs for distance estimations)
data_filt_behav <- fulldata[!is.na(fulldata$EstimatedDistance),]
nrow(fulldata)-nrow(data_filt_behav) # how many trials
length(unique(fulldata$ID[is.na(fulldata$EstimatedDistance)])) # from how many participants

# remove trials with no cardiac data (either due to temporary absence of ecg signal: 88 trials or too noisy signal: 24 trials; 112 in total)
data_filt_ecg <- data_filt_behav[!is.na(data_filt_behav$systolength),]
nrow(data_filt_behav)-nrow(data_filt_ecg)
length(unique(fulldata$ID[is.na(fulldata$systolength)]))

# save consolidated data after removal of NAs
data <- data_filt_ecg
rm(data_filt_behav)
rm(data_filt_ecg)

# Log Localization Error (due to its non-normal distriubution)
data$LocalizationErrorLog <- log(data$LocalizationError)
#hist(data$LocalizationError, breaks = 100)

# remove trials with untypically large Localization Errors within subject (LE): LE > avg(LE) + 3*sd(LE)
thrshlds_b <- data %>% 
            group_by(ID) %>% 
            summarize(thrsh_hi = mean(LocalizationErrorLog, na.rm = TRUE) + 3 * sd(LocalizationErrorLog, na.rm = TRUE)) 


fullfltrd_1b <- inner_join(data, thrshlds_b, by = 'ID') %>% 
               filter(LocalizationErrorLog <= thrsh_hi) %>% 
               select(-c(thrsh_hi))

# how many trials were excluded?
cat('How many trials were excluded in total?\n')
cat(dim(data)[1] - dim(fullfltrd_1b)[1])

# how many trials should be removed at the subject level (due to LE)?
incl_b      <- data    %>% group_by(ID) %>% count()
excl_trial_b <- fullfltrd_1b %>% group_by(ID) %>% count()
comparison_b <- data.frame(incl_b, excl_trial_b)
comparison_b <- comparison_b %>% select(ID, n, n.1)
colnames(comparison_b) <- c('ID', 'INCL', 'EXCL')
comparison_b$diff_trials <- comparison_b$INCL - comparison_b$EXCL
comparison_b$percent_rm  <- (comparison_b$diff_trials / comparison_b$INCL) * 100
describe(comparison_b$percent_rm) # number
describe(comparison_b$diff_trials) # proprtion %

# assign a variable specyfing whether LE value is an outlier
for (s in unique(data$ID)){
for (t in unique(data$totTrial[data$ID == s])) {
ifelse(data$LocalizationErrorLog[data$ID == s & data$totTrial == t] > thrshlds_b$thrsh_hi[thrshlds_b$ID==s], outlier <- "outlier", outlier <- "non_outlier")
data$LE_outlier[data$ID == s & data$totTrial == t] <- outlier 
}}

# plot behavioral data - prior to LE-based exclusions (optional: export 5 x 5 cm)
group_col <- as.character(data$LE_outlier)            
group_col[group_col == "outlier"] <- scales::alpha("darkorange", 0.5)
group_col[group_col == "non_outlier"] <- scales::alpha("gray20", 0.2)
scatter.smooth(data$RealDistance, data$EstimatedDistance, xlim = c(1.4,5.6), ylim = c(0.5,11.5), cex = 0.2, col = group_col, xlab = "True Distance", ylab = "Estimated Distance", main = "Behavioral data (prior to Localization error-based exclusions)", cex.main = 0.8)
# create an identity line using a customized linear model
x<-0:7
y<-0:7
new <- data.frame(x = seq(0, 6, 0.1))
lines(new$x, predict(lm(y~x), new),col= scales::alpha("dodgerblue", alpha = 0.7),lty= 2, lwd = 1.6)

#plot behavioral data - after to LE-based exclusions 
d <- data[data$LE_outlier == "non_outlier",]
scatter.smooth(d$RealDistance, d$EstimatedDistance, xlim = c(1.4,5.6), ylim = c(0.5,8.5), cex = 0.05, col = scales::alpha("gray20", 0.4) , xlab = "True Distance", ylab = "Estimated Distance", main = "Behavioral data (after Localization error-based exclusions)", cex.main = 0.8)

# create an identity line using a customized linear model
x<-0:7
y<-0:7
new <- data.frame(x = seq(0, 6, 0.1))
lines(new$x, predict(lm(y~x), new),col= scales::alpha("dodgerblue", alpha = 0.8),lty= 2, lwd = 1.6)

```


<a name="S5"></a>
&nbsp;

#####**5. Exclusions based on distance errors (individual subjects)** 

```{r}

## remove subjects with more than three standard deviations above or below the sample mean of Distance Error

# get subject means
ID_means_b <- fullfltrd_1b %>% group_by(ID) %>% 
                            summarize(mean_DE = mean(DistanceError, na.rm = TRUE))

# get sample mean & SD
grand_mean_DistanceError <- mean(ID_means_b$mean_DE)
grand_sd_DistanceError   <- sd(ID_means_b$mean_DE)

# filter-out subjects
fltrd_IDs_b <- ID_means_b %>% filter(mean_DE < grand_mean_DistanceError + 3 * grand_sd_DistanceError) %>% filter(mean_DE > grand_mean_DistanceError - 3 * grand_sd_DistanceError) 

# join frames on ID (filter the full data)
fullfltrd_2b <- inner_join(fltrd_IDs_b, fullfltrd_1b, by = 'ID') %>%
               select(-mean_DE)

# how many participants were excluded?
cat('How many participants were excluded?\n')
cat(dim(fullfltrd_1b %>% group_by(ID) %>% count())[1] - dim(fullfltrd_2b %>% group_by(ID) %>% count())[1])

```

<a name="S6"></a>
&nbsp;

#####**6. Exclusions based on cardiac data (individual trials)** 

```{r}

## remove trials with untypically long/short systolic intervals
thrshlds_t <- data %>% group_by(ID) %>% summarize(thrsh_hi = mean(systolength, na.rm = TRUE) + 3 * sd(systolength, na.rm = TRUE), thrsh_lo = mean(systolength, na.rm = TRUE) - 3 * sd(systolength, na.rm = TRUE)) 

# remove rows with NA in cardiac data
data_filt <- data %>%  filter(!(is.na(systolength)))

fullfltrd_1t <- inner_join(data_filt, thrshlds_t, by = 'ID') %>% 
               filter(systolength < thrsh_hi) %>% 
               filter(systolength > thrsh_lo) %>%
               select(-c(thrsh_lo, thrsh_hi))

# how many trials were excluded?
cat('How many trials were excluded in total?\n')
cat(dim(data_filt)[1] - dim(fullfltrd_1t)[1])

# how many trials should be removed at the subject level?
incl_t       <- data_filt %>% group_by(ID) %>% count()
excl_trial_t <- fullfltrd_1t %>% group_by(ID) %>% count()
comparison_t <- data.frame(incl_t, excl_trial_t)
comparison_t <- comparison_t %>% select(ID, n, n.1)
colnames(comparison_t) <- c('ID', 'INCL', 'EXCL')
comparison_t$diff_trials <- comparison_t$INCL - comparison_t$EXCL
comparison_t$percent_rm  <- (comparison_t$diff_trials / comparison_t$INCL) * 100
describe(comparison_t$diff_trials) # number
describe(comparison_t$percent_rm) # proportion %

# assign a variable specyfing whether systolic interval is an outlier
for (s in unique(data$ID)){
for (t in unique(data$totTrial[data$ID == s])) {
  
ifelse(data$systolength[data$ID == s & data$totTrial == t] > thrshlds_t$thrsh_hi[thrshlds_t$ID==s], outlier <- "outlier", outlier <- "non_outlier") 

ifelse(data$systolength[data$ID == s & data$totTrial == t] < thrshlds_t$thrsh_lo[thrshlds_t$ID==s], outlier <- "outlier", outlier <- outlier)    
data$SYS_outlier[data$ID == s & data$totTrial == t] <- outlier 
}
}

# how many outliers?
nrow(data[data$SYS_outlier == "outlier",])
```


Plot some shizzle (takes ages):
```{r}
# plot systole lengths (optional: export 5 x 5 cm)
group_col <- as.character(data$SYS_outlier)            
group_col[group_col == "outlier"] <- scales::alpha("darkorange", 0.7)
group_col[group_col == "non_outlier"] <- scales::alpha("gray20", 0.2)

scatter.smooth(data$RRLength, data$systolength, xlim = c(min(data$RRLength),max(data$RRLength)), ylim = c(min(data$systolength),max(data$systolength)), cex = 0.2, col = group_col, xlab = "RR interval", ylab = "Systole length",  main = "Cardiac data (excluded trials in orange)", cex.main = 0.8)

# Additional step: identify irregular R peaks (physiologically implausible length of the RR interval; e.g., due to recording errors, motion artefacts, or ventricular extrasystoles)
d <- data[data$SYS_outlier == "non_outlier",]
range(d$RRLength)
hist(d$RRLength, breaks = 100)

```

<a name="S7"></a>
&nbsp;

#####**7. Remove identified trials and save the preprocessed data** 

```{r}

data <- data[data$LE_outlier == "non_outlier",]
data <- data[data$SYS_outlier == "non_outlier",]

# Check whether any of participants had more than 30% of trials excluded based on trial-level criteria or due to data loss
trials_per_subject <- data %>% group_by(ID) %>% count()
trials_per_subject$percent <- (trials_per_subject$n/720) * 100
exclusion_list <- unique(trials_per_subject$ID[trials_per_subject$percent < 70])
data <- data[!(data$ID %in% exclusion_list), ]

# describe proportion of trials (in %) retained for analysis (all subjects > 70%)
describe(trials_per_subject$percent)

# drop non-essential columns 
data <- select(data, -Training, -Phase, -LE_outlier, -SYS_outlier)

# save consolidated data (optional)
write.csv(data, paste0(VRCC_dir, "/Data/VRTask/VRCC_data_consolidated-2023-08-10.csv"), row.names = F)

```
