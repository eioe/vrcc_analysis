sum(data_clean$FWI > 110)
# Chunk 23
ggplot(data_clean, aes(FWI, MONEY)) + geom_point(color = color,
alpha = .2) +
xlab('Family Wealth Index') +
ylab('Wage') +
geom_smooth(color  = color2,
method ='loess') +
theme_minimal()
# Chunk 24
ggplot(data_clean, aes(CI, MONEY)) + geom_point(color = color,
alpha = .2) +
xlab('Competence Assesment Index') +
ylab('Wage') +
geom_smooth(color  = color2,
method ='loess') +
theme_minimal()
# Chunk 25
ggplot(data_clean, aes(AQ, MONEY)) + geom_point(color = color,
alpha = .2) +
xlab('Ambitions Questionnaire Index') +
ylab('Wage') +
geom_smooth(color  = color2,
method ='loess') +
theme_minimal()
# Chunk 26
ggplot(data_clean, aes(II, MONEY)) + geom_point(color = color,
alpha = .2) +
xlab('Index of Work Involvement') +
ylab('Wage') +
geom_smooth(color  = color2,
method ='loess') +
theme_minimal()
# Chunk 27
model_1 <- lm(MONEY ~ ., data = data_clean)
# Chunk 28
summary(model_1)
# Chunk 29
# model_1_vif = vif(model_1)
# cat("Tolerance: ", 1 / model_1_vif)
model_1_vif = vif(model_1)
print(model_1_vif)
cat("\nTolerance: ", 1 / model_1_vif)
summary(data)
cor(data_clean)
# Correlation matrix
cor_mtrx <- cor(data_clean)
print(cor_mtrx)
cor_mtrx[cor_mtrx > .8]
print(cor.test(data_clean$AQ, data_clean$II))
autoplot(model_1)
autoplot(model_1) + theme_minimal()
autoplot(model_1, colour = color, smooth.colour = color2) + theme_minimal()
autoplot(model_1, colour = color, smooth.colour = color2, alpha = .5) + theme_minimal()
autoplot(model_1, colour = color, smooth.colour = color2, alpha = .3) + theme_minimal()
data_clean[400,]
library(olsrr)
install.packages('olsrr')
install.packages('olsrr')
install.packages("olsrr")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
path = "C:\\Users\\aleksander.molak\\Documents\\Personal\\Psych\\LINEAR_REGRESSION\\HMWRK1"
data_file = "ESP_DATA6_HOMEWORK1.SAV"
color  = '#195e8c'
color2 = '#d4ff00'
color3 = '#92c1cc'
color4 = '#ffbf00'
# Chunk 2
library(foreign)
library(dplyr)
library(ggplot2)
library(ggfortify)
library(olsrr)
library(psych)
library(car)
library(dummies)
# Chunk 3
data <- read.spss(file.path(path, data_file), to.data.frame = TRUE)
# Chunk 4
# Number of observations
dim(data)[1]
# Chunk 5
summary(data)
# Chunk 6
# Recode `SEX`
data$SEX <- dplyr::recode(data$SEX, male = 0, female = 1)
# Chunk 7
edu <- data %>% select(EDUC)
edu_dummy <- dummy(edu$EDUC, sep = '_')
data_ohe <- cbind(data, edu_dummy)
# Chunk 8
data_ohe <- plyr::rename(data_ohe,
replace = c('EDUC_profiled highschool' = 'EDUC_profiled_highschool',
'EDUC_general highschool'  = 'EDUC_general_highschool'))
# Chunk 9
# #### Knitr throws an error here: save the data to csv and re-read ####
# data_clean <- data_ohe %>% select(-c(EDUC))
# data_clean <- data_clean %>% select(-c(EDUC_higher))
# #
# write.csv(data_clean, file.path(path, 'data_clean.csv'), row.names = FALSE)
data_clean <- read.csv(file.path(path, 'data_clean.csv'))
# Chunk 10
# Histogram of DV - MONEY
ggplot(data_clean, aes(MONEY)) + geom_histogram(bins=7, fill=color, alpha=.7) +
xlab('Wage') +
ylab('Count') +
theme_minimal()
# Chunk 11
# Histogram of DV - MONEY
ggplot(data_clean, aes(FWI)) + geom_histogram(bins=7, fill=color, alpha=.7) +
xlab('Family Wealth Index') +
ylab('Count') +
theme_minimal()
# Chunk 12
# Histogram of DV - MONEY
ggplot(data_clean, aes(CI)) + geom_histogram(bins=7, fill=color, alpha=.7) +
xlab('Competence Assessment Index') +
ylab('Count') +
theme_minimal()
# Chunk 13
# Histogram of DV - MONEY
ggplot(data_clean, aes(AQ)) + geom_histogram(bins=7, fill=color, alpha=.7) +
xlab('Ambitions Questionnaire Score') +
ylab('Count') +
theme_minimal()
# Chunk 14
# Histogram of DV - MONEY
ggplot(data_clean, aes(II)) + geom_histogram(bins=7, fill=color, alpha=.7) +
xlab('Index of work involvement') +
ylab('Count') +
theme_minimal()
# Chunk 15
ggplot(data_clean, aes(FWI, MONEY)) + geom_point(color = color,
alpha = .2) +
xlab('Family Wealth Index') +
ylab('Wage') +
geom_smooth(color  = color2,
method ='loess') +
theme_minimal()
# Chunk 16
data_clean$FWI[data_clean$FWI > 100]
# Chunk 17
length(data_clean$FWI[data_clean$FWI > 100])
# Chunk 18
length(data_clean$FWI[data_clean$FWI > 110])
# Chunk 19
data_clean$FWI[data_clean$FWI > 110]
# Chunk 20
for (col in colnames(data_clean)) {
cat('Variable', col, 'values for all records with FWI > 110:\n', sep = ' ')
cat(unlist(data_clean %>% filter(FWI > 110) %>% select(col)))
cat('\n\n')
}
# Chunk 21
# Remove obs with `FWI` > 110
data_clean <- data_clean %>% filter(FWI <= 110)
# Chunk 22
# Sanity check
sum(data_clean$FWI > 110)
# Chunk 23
ggplot(data_clean, aes(FWI, MONEY)) + geom_point(color = color,
alpha = .2) +
xlab('Family Wealth Index') +
ylab('Wage') +
geom_smooth(color  = color2,
method ='loess') +
theme_minimal()
# Chunk 24
ggplot(data_clean, aes(CI, MONEY)) + geom_point(color = color,
alpha = .2) +
xlab('Competence Assesment Index') +
ylab('Wage') +
geom_smooth(color  = color2,
method ='loess') +
theme_minimal()
# Chunk 25
ggplot(data_clean, aes(AQ, MONEY)) + geom_point(color = color,
alpha = .2) +
xlab('Ambitions Questionnaire Index') +
ylab('Wage') +
geom_smooth(color  = color2,
method ='loess') +
theme_minimal()
# Chunk 26
ggplot(data_clean, aes(II, MONEY)) + geom_point(color = color,
alpha = .2) +
xlab('Index of Work Involvement') +
ylab('Wage') +
geom_smooth(color  = color2,
method ='loess') +
theme_minimal()
# Chunk 27
model_1 <- lm(MONEY ~ ., data = data_clean)
# Chunk 28
summary(model_1)
# Chunk 29
autoplot(model_1, colour = color, smooth.colour = color2, alpha = .3) + theme_minimal()
# Chunk 30
#
# Chunk 31
# Correlation matrix
cor_mtrx <- cor(data_clean)
print(cor_mtrx)
# Chunk 32
# Check all corrs > .8
print(cor_mtrx[cor_mtrx > .8])
print(cor.test(data_clean$AQ, data_clean$II))
# Chunk 33
model_1_vif = vif(model_1)
print(model_1_vif)
cat("\nTolerance: ", 1 / model_1_vif)
unlink('Personal/Psych/LINEAR_REGRESSION/HMWRK1/regression_1_cache', recursive = TRUE)
# Utils
library(dplyr)
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
# Plotting and tables
library(ggplot2)
library(sjPlot)
# Statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)
# Load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
# Utils
library(dplyr)
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
# Plotting and tables
library(ggplot2)
library(sjPlot)
# Statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)
# Load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
setwd('C:\\Users\\aleksander.molak\\Documents\\Personal\\Fear from  heart - Central Kollegs\\centralkollegs18')
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
# Utils
library(dplyr)
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
# Plotting and tables
library(ggplot2)
library(sjPlot)
# Statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)
# Load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
# Utils
library(dplyr)
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
# Plotting and tables
library(ggplot2)
library(sjPlot)
# Statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)
# Load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
# Set up the fulldata directory
VRCC_dir         <- here()
data_dir         <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path  <- here("./Data/VRTask/Ratings/Backup_15-07-2019.xlsx")
sess_info_folder <- here('./Data/VRTask/Logfiles/ExpSubjects')
# Build the fulldataset (Behavioral/VR data)
cat('\n\nReading bahavioral and VR data...\n\n')
fulldata <- build_dataset(data_dir)
# Get the summary of questionnaire data
cat('\n\nReading questionnaire data...\n\n')
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)
### Removing the subjects with no cardiac data (temporary - to be decided)
# # Drop unused data from five subjects
pre_exclusions <- c("S11", "S13", "S18", "S21", "S44")
# from behavioral data:
length(unique(fulldata$ID)) # sample size before
fulldata <- fulldata[!(fulldata$ID %in% pre_exclusions), ]
length(unique(fulldata$ID))  # sample size after
# from questionnaire data:
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))
q_data
View(q_data)
getwd()
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
# Utils
library(dplyr)
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
# Plotting and tables
library(ggplot2)
library(sjPlot)
# Statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)
# Load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
install.packages('mosaic')
install.packages("mosaic")
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
# Utils
library(dplyr)
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
# Plotting and tables
library(ggplot2)
library(sjPlot)
# Statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)
# Load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
# Set up the fulldata directory
VRCC_dir         <- here()
data_dir         <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path  <- here("./Data/VRTask/Ratings/Backup_15-07-2019.xlsx")
sess_info_folder <- here('./Data/VRTask/Logfiles/ExpSubjects')
# Build the fulldataset (Behavioral/VR data)
cat('\n\nReading bahavioral and VR data...\n\n')
fulldata <- build_dataset(data_dir)
# Get the summary of questionnaire data
cat('\n\nReading questionnaire data...\n\n')
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)
### Removing the subjects with no cardiac data (temporary - to be decided)
# # Drop unused data from five subjects
pre_exclusions <- c("S11", "S13", "S18", "S21", "S44")
# from behavioral data:
length(unique(fulldata$ID)) # sample size before
fulldata <- fulldata[!(fulldata$ID %in% pre_exclusions), ]
length(unique(fulldata$ID))  # sample size after
# from questionnaire data:
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))
# Set up the fulldata directory
VRCC_dir         <- here()
data_dir         <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path  <- here("./Data/VRTask/Ratings/Backup_15-07-2019.xlsx")
sess_info_folder <- here('./Data/VRTask/Logfiles/ExpSubjects')
# Build the fulldataset (Behavioral/VR data)
cat('\n\nReading bahavioral and VR data...\n\n')
fulldata <- build_dataset(data_dir)
# Get the summary of questionnaire data
cat('\n\nReading questionnaire data...\n\n')
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)
### Removing the subjects with no cardiac data (temporary - to be decided)
# # Drop unused data from five subjects
pre_exclusions <- c("S11", "S13", "S18", "S21", "S44")
# from behavioral data:
length(unique(fulldata$ID)) # sample size before
fulldata <- fulldata[!(fulldata$ID %in% pre_exclusions), ]
length(unique(fulldata$ID))  # sample size after
# from questionnaire data:
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))
# Set up the fulldata directory
VRCC_dir         <- here()
data_dir         <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path  <- here("./Data/VRTask/Ratings/Backup_15-07-2019.xlsx")
sess_info_folder <- here('./Data/VRTask/Logfiles/ExpSubjects')
# Build the fulldataset (Behavioral/VR data)
cat('\n\nReading bahavioral and VR data...\n\n')
fulldata <- build_dataset(data_dir)
# Get the summary of questionnaire data
cat('\n\nReading questionnaire data...\n\n')
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)
### Removing the subjects with no cardiac data (temporary - to be decided)
# # Drop unused data from five subjects
pre_exclusions <- c("S11", "S13", "S18", "S21", "S44")
# from behavioral data:
length(unique(fulldata$ID)) # sample size before
fulldata <- fulldata[!(fulldata$ID %in% pre_exclusions), ]
length(unique(fulldata$ID))  # sample size after
# from questionnaire data:
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)
getcwd()
getwd()
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
# Utils
library(dplyr)
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
# Plotting and tables
library(ggplot2)
library(sjPlot)
# Statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)
# Load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
# Set up the fulldata directory
VRCC_dir         <- here()
data_dir         <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path  <- here("./Data/VRTask/Ratings/Backup_15-07-2019.xlsx")
sess_info_folder <- here('./Data/VRTask/Logfiles/ExpSubjects')
# Build the fulldataset (Behavioral/VR data)
cat('\n\nReading bahavioral and VR data...\n\n')
fulldata <- build_dataset(data_dir)
# Get the summary of questionnaire data
cat('\n\nReading questionnaire data...\n\n')
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)
### Removing the subjects with no cardiac data (temporary - to be decided)
# # Drop unused data from five subjects
pre_exclusions <- c("S11", "S13", "S18", "S21", "S44")
# from behavioral data:
length(unique(fulldata$ID)) # sample size before
fulldata <- fulldata[!(fulldata$ID %in% pre_exclusions), ]
length(unique(fulldata$ID))  # sample size after
# from questionnaire data:
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))
