length(unique(fulldata$ID))  # sample size after
# remove five subjects from questionnaire data
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))
# drop unused levels
fulldata <- droplevels(fulldata)
# compute distance measures & add to the dataset
fulldata <- fulldata %>%
mutate(DistanceError = (EstimatedDistance - RealDistance),
DistanceErrorAbs = abs(DistanceError),
DistanceErrorNorm = (DistanceError / RealDistance) * 100,
DistanceErrorNormAbs = abs(DistanceErrorNorm),
LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
AngularErrorRad = compute_angles(EstimatedPosition, TruePosition)) %>%
mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)
# insert NAs when no estimation was made
fulldata$LocalizationError[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$LocalizationErrorNorm[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$AngularErrorRad[is.na(fulldata$EstimatedDistance)] <- NA
~TRUE
!TRUE
pracma::cross(c(1,0,0), c(0,1,0))
pracma::cross(c(0,1,0), c(1, 0,0))
c(0,0,1)%*%c(1,0,1)
c(0,0,1)%*%c(-1,0,1)
? %*%
oo <- c(0,0,1)%*%c(-1,0,1) / (norm(c(0,0,1), type="2") * norm(c(-1,0,1), type="2"))
oo
acos(oo)
oo <- c(0,0,1)%*%c(1,0,1) / (norm(c(0,0,1), type="2") * norm(c(1,0,1), type="2"))
acos(oo)
c(0,0,1)%*%c(-1,0,1)
c(0,0,1)%*%c(1,0,1)
c(1,0,0)%*%c(1,0,1)
c(1,0,0)%*%c(1,0,-1)
c(1,0,0)*c(1,0,-1)
c(1,0)%*%c(1,1)
c(1,0)%*%c(1,-1)
c(1,0)%*%c(-1,1)
pracma::cross(c(1,0),c(1,1))
pracma::cross(c(1,0,0),c(1,0,1))
plot(fulldata$RealDistance, fulldata$AngleErrDeg)
lm(fulldata$RealDistance~ fulldata$AngleErrDeg)
summary(lm(fulldata$RealDistance~ fulldata$AngleErrDeg))
get_angle <- function(pos_1, pos_2, abs_value=FALSE){
dotprod <- pos_1 %*% pos_2
norm_1 <- norm(pos_1, type="2")
norm_2 <- norm(pos_2, type="2")
theta <- acos(dotprod / (norm_1 * norm_2))
as.numeric(theta)
if (!abs_value) {
if (!(length(pos_1) == length(pos_2) & length(pos_1) == 3)) {
stop("Cannot calculate abs. value via crossproduct for 2D input.")
}
crossprod <- pracma::cross(pos_1, pos_2)
theta <- sign(crossprod) * theta
}
return(theta)
}
get_angle(c(1,0,0), c(1,0,1))
get_angle <- function(pos_1, pos_2, abs_value=FALSE){
dotprod <- pos_1 %*% pos_2
norm_1 <- norm(pos_1, type="2")
norm_2 <- norm(pos_2, type="2")
theta <- acos(dotprod / (norm_1 * norm_2))
as.numeric(theta)
if (!abs_value) {
if (!(length(pos_1) == length(pos_2) & length(pos_1) == 3)) {
stop("Cannot calculate abs. value via crossproduct for 2D input.")
}
crossprod <- pracma::cross(pos_1, pos_2)
theta <- sign(crossprod[2]) * theta
}
return(theta)
}
get_angle(c(1,0,0), c(1,0,1))
get_angle(c(1,0,0), c(1,0,-1))
# r setup
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
# utils
library(dplyr)
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
library(dplR)
# plotting and tables
library(ggplot2)
library(sjPlot)
# statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)
# load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/stats_utils.r"))
# set up the fulldata directory
VRCC_dir         <- here()
data_dir         <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path  <- here("./Data/VRTask/Ratings/Ratings_cleaned_AM_2020_10_20.xlsx")
sess_info_folder <- here('./Data/VRTask/Logfiles/ExpSubjects')
# build the fulldataset (Behavioral/VR data)
cat('\n\nReading bahavioral and VR data...\n\n')
fulldata <- build_dataset(data_dir, part='main')
traindata <- build_dataset(data_dir, part='training')
# get the summary of questionnaire data
cat('\n\nReading questionnaire data...\n\n')
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)
# specify unused data from five subjects (different technical issues)
pre_exclusions <- c("S11", "S13", "S18", "S21", "S44")
# remove five subjects from behavioral data
length(unique(fulldata$ID)) # sample size before
fulldata <- fulldata[!(fulldata$ID %in% pre_exclusions), ]
length(unique(fulldata$ID))  # sample size after
# remove five subjects from questionnaire data
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))
# drop unused levels
fulldata <- droplevels(fulldata)
# compute distance measures & add to the dataset
fulldata <- fulldata %>%
mutate(DistanceError = (EstimatedDistance - RealDistance),
DistanceErrorAbs = abs(DistanceError),
DistanceErrorNorm = (DistanceError / RealDistance) * 100,
DistanceErrorNormAbs = abs(DistanceErrorNorm),
LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
AngularErrorRad = compute_angles(EstimatedPosition, TruePosition)) %>%
mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)
# compute distance measures & add to the dataset
fulldata <- fulldata %>%
mutate(DistanceError = (EstimatedDistance - RealDistance),
DistanceErrorAbs = abs(DistanceError),
DistanceErrorNorm = (DistanceError / RealDistance) * 100,
DistanceErrorNormAbs = abs(DistanceErrorNorm),
LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
AngularErrorRad = compute_angles(EstimatedPosition, TruePosition, abs_value = TRUE)) %>%
mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)
# insert NAs when no estimation was made
fulldata$LocalizationError[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$LocalizationErrorNorm[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$AngularErrorRad[is.na(fulldata$EstimatedDistance)] <- NA
# r setup
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
# utils
library(dplyr)
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
library(dplR)
# plotting and tables
library(ggplot2)
library(sjPlot)
# statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)
# load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/stats_utils.r"))
# set up the fulldata directory
VRCC_dir         <- here()
data_dir         <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path  <- here("./Data/VRTask/Ratings/Ratings_cleaned_AM_2020_10_20.xlsx")
sess_info_folder <- here('./Data/VRTask/Logfiles/ExpSubjects')
# build the fulldataset (Behavioral/VR data)
cat('\n\nReading bahavioral and VR data...\n\n')
fulldata <- build_dataset(data_dir, part='main')
traindata <- build_dataset(data_dir, part='training')
# get the summary of questionnaire data
cat('\n\nReading questionnaire data...\n\n')
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)
# specify unused data from five subjects (different technical issues)
pre_exclusions <- c("S11", "S13", "S18", "S21", "S44")
# remove five subjects from behavioral data
length(unique(fulldata$ID)) # sample size before
fulldata <- fulldata[!(fulldata$ID %in% pre_exclusions), ]
length(unique(fulldata$ID))  # sample size after
# remove five subjects from questionnaire data
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))
# drop unused levels
fulldata <- droplevels(fulldata)
# compute distance measures & add to the dataset
fulldata <- fulldata %>%
mutate(DistanceError = (EstimatedDistance - RealDistance),
DistanceErrorAbs = abs(DistanceError),
DistanceErrorNorm = (DistanceError / RealDistance) * 100,
DistanceErrorNormAbs = abs(DistanceErrorNorm),
LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
AngularErrorRad = compute_angles(EstimatedPosition, TruePosition, abs_value = TRUE)) %>%
mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)
# insert NAs when no estimation was made
fulldata$LocalizationError[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$LocalizationErrorNorm[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$AngularErrorRad[is.na(fulldata$EstimatedDistance)] <- NA
# compute distance measures & add to the dataset
fulldata <- fulldata %>%
mutate(DistanceError = (EstimatedDistance - RealDistance),
DistanceErrorAbs = abs(DistanceError),
DistanceErrorNorm = (DistanceError / RealDistance) * 100,
DistanceErrorNormAbs = abs(DistanceErrorNorm),
LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
AngularErrorRadAbs = compute_angles(EstimatedPosition, TruePosition, abs_value = TRUE),
AngularErrorRad = compute_angles(EstimatedPosition, TruePosition, abs_value = FALSE)) %>%
mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
# compute distance measures & add to the dataset
fulldata <- fulldata %>%
mutate(DistanceError = (EstimatedDistance - RealDistance),
DistanceErrorAbs = abs(DistanceError),
DistanceErrorNorm = (DistanceError / RealDistance) * 100,
DistanceErrorNormAbs = abs(DistanceErrorNorm),
LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
AngularErrorRadAbs = compute_angles(EstimatedPosition, TruePosition, abs_value = TRUE),
AngularErrorRad = compute_angles(EstimatedPosition, TruePosition, abs_value = FALSE)) %>%
mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
# compute distance measures & add to the dataset
fulldata <- fulldata %>%
mutate(DistanceError = (EstimatedDistance - RealDistance),
DistanceErrorAbs = abs(DistanceError),
DistanceErrorNorm = (DistanceError / RealDistance) * 100,
DistanceErrorNormAbs = abs(DistanceErrorNorm),
LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
AngularErrorRadAbs = compute_angles(EstimatedPosition, TruePosition, abs_value = TRUE),
AngularErrorRad = compute_angles(EstimatedPosition, TruePosition, abs_value = FALSE)) %>%
mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)
# insert NAs when no estimation was made
fulldata$LocalizationError[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$LocalizationErrorNorm[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$AngularErrorRad[is.na(fulldata$EstimatedDistance)] <- NA
hist(fulldata$AngularErrorRad)
hist(fulldata$AngularErrorRad, bins=100)
? hist
hist(fulldata$AngularErrorRad, breaks = 100)
hist(fulldata$AngularErrorRad, breaks = 1000)
abline(v=0, 'r')
abline(v=0, col='r')
abline(v=0, col='red')
hist(fulldata$AngularErrorRad, breaks = 1000)
hist(fulldata$AngularErrorRadAbs, breaks = 1000)
# r setup
knitr::opts_chunk$set(echo = TRUE)
basic_color <- '#195e8c'
# utils
library(dplyr)
library(here)
library(haven)
library(readr)
library(tibble)
library(purrr)
library(mosaic)
library(stringr)
library(dplR)
# plotting and tables
library(ggplot2)
library(sjPlot)
# statistical tools
library(lme4)
library(lmtest)
library(lmerTest)
library(car)
library(BayesFactor)
library(effsize)
library(psych)
# load helper functions
source(here("./Code/Analyses/VRTask/Utils/get_cardio_info.R"))
source(here("./Code/Analyses/VRTask/Utils/read_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/distance_utils.r"))
source(here("./Code/Analyses/VRTask/Utils/stats_utils.r"))
# set up the fulldata directory
VRCC_dir         <- here()
data_dir         <- here("Data/VRTask/Logfiles/ExpSubjects")
qstnr_data_path  <- here("./Data/VRTask/Ratings/Ratings_cleaned_AM_2020_10_20.xlsx")
sess_info_folder <- here('./Data/VRTask/Logfiles/ExpSubjects')
# build the fulldataset (Behavioral/VR data)
cat('\n\nReading bahavioral and VR data...\n\n')
fulldata <- build_dataset(data_dir, part='main')
traindata <- build_dataset(data_dir, part='training')
# get the summary of questionnaire data
cat('\n\nReading questionnaire data...\n\n')
q_data <- get_questnr_data(qstnr_data_path, sess_info_folder)
# specify unused data from five subjects (different technical issues)
pre_exclusions <- c("S11", "S13", "S18", "S21", "S44")
# remove five subjects from behavioral data
length(unique(fulldata$ID)) # sample size before
fulldata <- fulldata[!(fulldata$ID %in% pre_exclusions), ]
length(unique(fulldata$ID))  # sample size after
# remove five subjects from questionnaire data
length(unique(q_data$subject)) # sample size before
q_data <- q_data[!(q_data$subject %in% pre_exclusions), ]
length(unique(q_data$subject))
# drop unused levels
fulldata <- droplevels(fulldata)
# compute distance measures & add to the dataset
fulldata <- fulldata %>%
mutate(DistanceError = (EstimatedDistance - RealDistance),
DistanceErrorAbs = abs(DistanceError),
DistanceErrorNorm = (DistanceError / RealDistance) * 100,
DistanceErrorNormAbs = abs(DistanceErrorNorm),
LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
AngularErrorRadAbs = compute_angles(EstimatedPosition, TruePosition, abs_value = TRUE),
AngularErrorRad = compute_angles(EstimatedPosition, TruePosition, abs_value = FALSE)) %>%
mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)
# insert NAs when no estimation was made
fulldata$LocalizationError[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$LocalizationErrorNorm[is.na(fulldata$EstimatedDistance)] <- NA
fulldata$AngularErrorRad[is.na(fulldata$EstimatedDistance)] <- NA
# compute distance measures & add to the dataset
traindata <- traindata %>%
mutate(DistanceError = (EstimatedDistance - RealDistance),
DistanceErrorAbs = abs(DistanceError),
DistanceErrorNorm = (DistanceError / RealDistance) * 100,
DistanceErrorNormAbs = abs(DistanceErrorNorm),
LocalizationError = compute_euclidean_distances(EstimatedPosition, TruePosition),
LocalizationErrorNorm = (LocalizationError / RealDistance) * 100,
AngularErrorRad = compute_angles(EstimatedPosition, TruePosition)) %>%
mutate(totTrial = Trial + (Round - 1) * max(Trial)) # labels the trials with sequential numbers over the whole experiment (1-720)
# insert NAs when no estimation was made
traindata$LocalizationError[is.na(traindata$EstimatedDistance)] <- NA
traindata$LocalizationErrorNorm[is.na(traindata$EstimatedDistance)] <- NA
traindata$AngularErrorRad[is.na(traindata$EstimatedDistance)] <- NA
td <- traindata %>%
mutate(EstDist_man = compute_euclidean_distances(EstimatedPosition, HeadsetPosition),
RealDist_man = compute_euclidean_distances(TruePosition, HeadsetPosition),
DistErr_man = (EstDist_man - RealDist_man))
td <- td %>%
mutate(DE_diff = (DistErr_man - DistanceError))
fd <- fulldata %>%
mutate(EstDist_man = compute_euclidean_distances(EstimatedPosition, HeadsetPosition),
RealDist_man = compute_euclidean_distances(TruePosition, HeadsetPosition),
DistErr_man = (EstDist_man - RealDist_man))
fd <- fd %>%
mutate(DE_diff = (DistErr_man - DistanceError))
# get the list of subjects with full ecg data
subjects_list <- list.files(here("Data/VRTask/Cardio/ExpSubjects/02_Peaks/Events"))
subjects_list <- str_remove(subjects_list, "VRCC_")
subjects_list <- str_remove(subjects_list, ".csv")
cardio_data   <- NULL
# add cardiac data
for (subj_ID in subjects_list) {
cardio_temp <- get_cardio_info(fulldata, subj_ID)
cardio_data <- bind_rows(cardio_data, cardio_temp)
}
# join the data
fulldata <- full_join(fulldata, cardio_data)
# save the preprocessed data (optional)
#write.csv(fulldata, paste0(VRCC_dir, "/Data/VRTask/VRCC_data_unfiltered"), row.names = F)
# read the preprocessed data (optional)
#fulldata <- read.csv(file = paste0(VRCC_dir,"/Data/VRTask/VRCC_data_unfiltered"))
# add unique row ID
fulldata$row_ID <- paste0(fulldata$ID, '_', fulldata$Round, '_', fulldata$Trial)
fulldata$ID <- as.factor(fulldata$ID)
# remove trials with no distance estimation (NAs for distance estimations)
data_filt_behav <- fulldata[!is.na(fulldata$EstimatedDistance),]
nrow(fulldata)-nrow(data_filt_behav) # how many trials
length(unique(fulldata$ID[is.na(fulldata$EstimatedDistance)])) # from how many participants
# remove trials with no cardiac data (either due to temporary absence of ecg signal: 88 trials or too noisy signal: 24 trials; 112 in total)
data_filt_ecg <- data_filt_behav[!is.na(data_filt_behav$systolength),]
nrow(data_filt_behav)-nrow(data_filt_ecg)
length(unique(fulldata$ID[is.na(fulldata$systolength)]))
# save consolidated data after removal of NAs
data <- data_filt_ecg
rm(data_filt_behav)
rm(data_filt_ecg)
# Log Localization Error (due to its non-normal distriubution)
data$LocalizationErrorLog <- log(data$LocalizationError)
#hist(data$LocalizationError, breaks = 100)
# remove trials with untypically large Localization Errors within subject (LE): LE > avg(LE) + 3*sd(LE)
thrshlds_b <- data %>%
group_by(ID) %>%
summarize(thrsh_hi = mean(LocalizationErrorLog, na.rm = TRUE) + 3 * sd(LocalizationErrorLog, na.rm = TRUE))
fullfltrd_1b <- inner_join(data, thrshlds_b, by = 'ID') %>%
filter(LocalizationErrorLog <= thrsh_hi) %>%
select(-c(thrsh_hi))
# how many trials were excluded?
cat('How many trials were excluded in total?\n')
cat(dim(data)[1] - dim(fullfltrd_1b)[1])
# how many trials should be removed at the subject level (due to LE)?
incl_b      <- data    %>% group_by(ID) %>% count()
excl_trial_b <- fullfltrd_1b %>% group_by(ID) %>% count()
comparison_b <- data.frame(incl_b, excl_trial_b)
comparison_b <- comparison_b %>% select(ID, n, n.1)
colnames(comparison_b) <- c('ID', 'INCL', 'EXCL')
comparison_b$diff_trials <- comparison_b$INCL - comparison_b$EXCL
comparison_b$percent_rm  <- (comparison_b$diff_trials / comparison_b$INCL) * 100
describe(comparison_b$percent_rm) # number
describe(comparison_b$diff_trials) # proprtion %
# assign a variable specyfing whether LE value is an outlier
for (s in unique(data$ID)){
for (t in unique(data$totTrial[data$ID == s])) {
ifelse(data$LocalizationErrorLog[data$ID == s & data$totTrial == t] > thrshlds_b$thrsh_hi[thrshlds_b$ID==s], outlier <- "outlier", outlier <- "non_outlier")
data$LE_outlier[data$ID == s & data$totTrial == t] <- outlier
}}
# plot behavioral data - prior to LE-based exclusions (optional: export 5 x 5 cm)
group_col <- as.character(data$LE_outlier)
group_col[group_col == "outlier"] <- scales::alpha("darkorange", 0.5)
group_col[group_col == "non_outlier"] <- scales::alpha("gray20", 0.2)
scatter.smooth(data$RealDistance, data$EstimatedDistance, xlim = c(1.4,5.6), ylim = c(0.5,11.5), cex = 0.2, col = group_col, xlab = "True Distance", ylab = "Estimated Distance", main = "Behavioral data (prior to Localization error-based exclusions)", cex.main = 0.8)
# create an identity line using a customized linear model
x<-0:7
y<-0:7
new <- data.frame(x = seq(0, 6, 0.1))
lines(new$x, predict(lm(y~x), new),col= scales::alpha("dodgerblue", alpha = 0.7),lty= 2, lwd = 1.6)
#plot behavioral data - after to LE-based exclusions
d <- data[data$LE_outlier == "non_outlier",]
scatter.smooth(d$RealDistance, d$EstimatedDistance, xlim = c(1.4,5.6), ylim = c(0.5,8.5), cex = 0.05, col = scales::alpha("gray20", 0.4) , xlab = "True Distance", ylab = "Estimated Distance", main = "Behavioral data (after Localization error-based exclusions)", cex.main = 0.8)
# create an identity line using a customized linear model
x<-0:7
y<-0:7
new <- data.frame(x = seq(0, 6, 0.1))
lines(new$x, predict(lm(y~x), new),col= scales::alpha("dodgerblue", alpha = 0.8),lty= 2, lwd = 1.6)
## remove subjects with more than three standard deviations above or below the sample mean of Distance Error
# get subject means
ID_means_b <- fullfltrd_1b %>% group_by(ID) %>%
summarize(mean_DE = mean(DistanceError, na.rm = TRUE))
# get sample mean & SD
grand_mean_DistanceError <- mean(ID_means_b$mean_DE)
grand_sd_DistanceError   <- sd(ID_means_b$mean_DE)
# filter-out subjects
fltrd_IDs_b <- ID_means_b %>% filter(mean_DE < grand_mean_DistanceError + 3 * grand_sd_DistanceError) %>% filter(mean_DE > grand_mean_DistanceError - 3 * grand_sd_DistanceError)
# join frames on ID (filter the full data)
fullfltrd_2b <- inner_join(fltrd_IDs_b, fullfltrd_1b, by = 'ID') %>%
select(-mean_DE)
# how many participants were excluded?
cat('How many participants were excluded?\n')
cat(dim(fullfltrd_1b %>% group_by(ID) %>% count())[1] - dim(fullfltrd_2b %>% group_by(ID) %>% count())[1])
## remove trials with untypically long/short systolic intervals
thrshlds_t <- data %>% group_by(ID) %>% summarize(thrsh_hi = mean(systolength, na.rm = TRUE) + 3 * sd(systolength, na.rm = TRUE), thrsh_lo = mean(systolength, na.rm = TRUE) - 3 * sd(systolength, na.rm = TRUE))
# remove rows with NA in cardiac data
data_filt <- data %>%  filter(!(is.na(systolength)))
fullfltrd_1t <- inner_join(data_filt, thrshlds_t, by = 'ID') %>%
filter(systolength < thrsh_hi) %>%
filter(systolength > thrsh_lo) %>%
select(-c(thrsh_lo, thrsh_hi))
# how many trials were excluded?
cat('How many trials were excluded in total?\n')
cat(dim(data_filt)[1] - dim(fullfltrd_1t)[1])
# how many trials should be removed at the subject level?
incl_t       <- data_filt %>% group_by(ID) %>% count()
excl_trial_t <- fullfltrd_1t %>% group_by(ID) %>% count()
comparison_t <- data.frame(incl_t, excl_trial_t)
comparison_t <- comparison_t %>% select(ID, n, n.1)
colnames(comparison_t) <- c('ID', 'INCL', 'EXCL')
comparison_t$diff_trials <- comparison_t$INCL - comparison_t$EXCL
comparison_t$percent_rm  <- (comparison_t$diff_trials / comparison_t$INCL) * 100
describe(comparison_t$diff_trials) # number
describe(comparison_t$percent_rm) # proportion %
# assign a variable specyfing whether systolic interval is an outlier
for (s in unique(data$ID)){
for (t in unique(data$totTrial[data$ID == s])) {
ifelse(data$systolength[data$ID == s & data$totTrial == t] > thrshlds_t$thrsh_hi[thrshlds_t$ID==s], outlier <- "outlier", outlier <- "non_outlier")
ifelse(data$systolength[data$ID == s & data$totTrial == t] < thrshlds_t$thrsh_lo[thrshlds_t$ID==s], outlier <- "outlier", outlier <- outlier)
data$SYS_outlier[data$ID == s & data$totTrial == t] <- outlier
}
}
# how many outliers?
nrow(data[data$SYS_outlier == "outlier",])
# plot systole lengths (optional: export 5 x 5 cm)
group_col <- as.character(data$SYS_outlier)
group_col[group_col == "outlier"] <- scales::alpha("darkorange", 0.7)
group_col[group_col == "non_outlier"] <- scales::alpha("gray20", 0.2)
scatter.smooth(data$RRLength, data$systolength, xlim = c(min(data$RRLength),max(data$RRLength)), ylim = c(min(data$systolength),max(data$systolength)), cex = 0.2, col = group_col, xlab = "RR interval", ylab = "Systole length",  main = "Cardiac data (excluded trials in orange)", cex.main = 0.8)
# Additional step: identify irregular R peaks (physiologically implausible length of the RR interval; e.g., due to recording errors, motion artefacts, or ventricular extrasystoles)
d <- data[data$SYS_outlier == "non_outlier",]
range(d$RRLength)
hist(d$RRLength, breaks = 100)
data <- data[data$LE_outlier == "non_outlier",]
data <- data[data$SYS_outlier == "non_outlier",]
# Check whether any of participants had more than 30% of trials excluded based on trial-level criteria or due to data loss
trials_per_subject <- data %>% group_by(ID) %>% count()
trials_per_subject$percent <- (trials_per_subject$n/720) * 100
exclusion_list <- unique(trials_per_subject$ID[trials_per_subject$percent < 70])
data <- data[!(data$ID %in% exclusion_list), ]
# describe proportion of trials (in %) retained for analysis (all subjects > 70%)
describe(trials_per_subject$percent)
# drop non-essential columns
data <- select(data, -Training, -Phase, -LE_outlier, -SYS_outlier)
# save consolidated data (optional)
write.csv(data, paste0(VRCC_dir, "/Data/VRTask/VRCC_data_consolidated-2023-07-20"), row.names = F)
